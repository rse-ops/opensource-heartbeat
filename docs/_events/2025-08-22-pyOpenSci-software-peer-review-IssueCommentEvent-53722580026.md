---
event_type: IssueCommentEvent
avatar: "https://avatars.githubusercontent.com/u/3303?"
user: jedbrown
date: 2025-08-22
repo_name: pyOpenSci/software-peer-review
html_url: https://github.com/pyOpenSci/software-peer-review/issues/331
repo_url: https://github.com/pyOpenSci/software-peer-review
---

<a href='https://github.com/jedbrown' target='_blank'>jedbrown</a> commented on issue <a href='https://github.com/pyOpenSci/software-peer-review/issues/331' target='_blank'>pyOpenSci/software-peer-review#331</a>.

<small>Suppose a human [types](https://devclass.com/2022/10/17/github-copilot-under-fire-as-dev-claims-it-emits-large-chunks-of-my-copyrighted-code/) `// sparse matrix transpose`, presses tab, and gets a page of code that still has namespaces from an existing library with copyright/attribution stripped. What does it mean that "accountability remains with humans"? What if the algorithmic system obfuscates just enough that it isn't obvious to the human that it's plagiarizing an existing library (violating that project's license)? Just because many people use a product doesn't mean it isn't manufacturing plausible deniability. If the claim is merely "I don't think copyright holders will successfully sue me for infringing", that is a statement about power rather than justice or consent....</small>

<a href='https://github.com/pyOpenSci/software-peer-review/issues/331' target='_blank'>View Comment</a>